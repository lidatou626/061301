import streamlit as st
import pandas as pd
import numpy as np
import time
import pickle
from surprise import Reader, Dataset, SVD
from surprise.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import jieba
from snownlp import SnowNLP
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="5Açº§æ™¯åŒºæŽ¨èç³»ç»Ÿ",
    page_icon="ðŸžï¸",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜å’Œä»‹ç»
st.title("å…¨å›½5Açº§æ™¯åŒºæŽ¨èç³»ç»Ÿ")
st.markdown("åŸºäºŽç”¨æˆ·è¯„è®ºçš„æƒ…æ„Ÿåˆ†æžå’Œå†…å®¹ç›¸ä¼¼åº¦çš„æ™¯åŒºæŽ¨è")

# åˆå§‹åŒ–çŠ¶æ€å˜é‡
if 'model_ready' not in st.session_state:
    st.session_state.model_ready = False
if 'data_ready' not in st.session_state:
    st.session_state.data_ready = False


# è‡ªå®šä¹‰å·¥å…·ç±»
class ScenicRecommender:
    def __init__(self):
        self.df = None
        self.algo = None
        self.scenic_reviews = None
        self.similarity_matrix = None
        self.scenic_index = None
        self.training_time = 0

    def load_and_preprocess_data(self, scenic_file, comment_file):
        try:
            # åŠ è½½æ•°æ®
            excel_file = pd.ExcelFile(scenic_file)
            df_scenic = excel_file.parse('5A')
            df_comment = pd.read_excel(comment_file)

            # æ•°æ®é¢„å¤„ç†
            df_scenic = df_scenic.dropna(subset=['dth_title'])
            df_comment = df_comment.dropna(subset=['æ™¯åŒºåç§°'])
            self.df = pd.merge(df_scenic, df_comment, left_on='dth_title', right_on='æ™¯åŒºåç§°', how='outer')

            # æå–å…³é”®è¯å’Œæƒ…æ„Ÿåˆ†æž
            def extract_keywords(text):
                if isinstance(text, float) and pd.isna(text):
                    return []
                return jieba.lcut(text)

            def get_sentiment_score(text):
                if isinstance(text, float) and pd.isna(text):
                    return None
                return SnowNLP(text).sentiments

            self.df['å…³é”®è¯'] = self.df['è¯„è®ºå†…å®¹'].apply(extract_keywords)
            self.df['æƒ…æ„Ÿå¾—åˆ†'] = self.df['è¯„è®ºå†…å®¹'].apply(get_sentiment_score)
            self.df['æ˜ å°„è¯„åˆ†'] = self.df['æƒ…æ„Ÿå¾—åˆ†'] * 4 + 1  # æ˜ å°„åˆ°1-5åˆ†

            st.session_state.data_ready = True
            return True
        except Exception as e:
            st.error(f"æ•°æ®åŠ è½½å‡ºé”™: {e}")
            return False

    def train_model(self):
        try:
            if self.df is None:
                st.error("è¯·å…ˆåŠ è½½æ•°æ®")
                return False

            # åˆ›å»ºReaderå’ŒDataset
            reader = Reader(rating_scale=(1, 5))
            data = Dataset.load_from_df(self.df[['ç”¨æˆ·ID', 'æ™¯åŒºåç§°', 'æ˜ å°„è¯„åˆ†']], reader)

            # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
            trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

            # è®­ç»ƒSVDæ¨¡åž‹
            start_time = time.time()
            self.algo = SVD(
                n_factors=50,
                n_epochs=20,
                lr_all=0.005,
                reg_all=0.02,
                random_state=42
            )
            self.algo.fit(trainset)
            self.training_time = time.time() - start_time

            # å†…å®¹æŽ¨è - åŸºäºŽTF-IDF
            self.scenic_reviews = self.df.groupby('æ™¯åŒºåç§°')['è¯„è®ºå†…å®¹'].agg(lambda x: ' '.join(x)).reset_index()

            # è‡ªå®šä¹‰åˆ†è¯å™¨
            def chinese_tokenizer(text):
                return jieba.lcut(text)

            vectorizer = TfidfVectorizer(
                tokenizer=chinese_tokenizer,
                stop_words=['çš„', 'äº†', 'å’Œ', 'æ˜¯', 'åœ¨'],
                ngram_range=(1, 2),
                max_features=5000
            )

            tfidf_matrix = vectorizer.fit_transform(self.scenic_reviews['è¯„è®ºå†…å®¹'])
            self.similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)
            self.scenic_index = {name: i for i, name in enumerate(self.scenic_reviews['æ™¯åŒºåç§°'])}

            st.session_state.model_ready = True
            return True
        except Exception as e:
            st.error(f"æ¨¡åž‹è®­ç»ƒå‡ºé”™: {e}")
            return False

    def get_similar_scenics(self, scenic_name, top_n=5):
        if scenic_name not in self.scenic_index:
            return pd.DataFrame({"æ™¯åŒºåç§°": [f"æŠ±æ­‰ï¼Œæ™¯åŒº '{scenic_name}' ä¸åœ¨æ•°æ®é›†ä¸­ã€‚"], "ç›¸ä¼¼åº¦å¾—åˆ†": [0]})

        idx = self.scenic_index[scenic_name]
        sim_scores = list(enumerate(self.similarity_matrix[idx]))
        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
        top_scenics = sim_scores[1:top_n + 1]

        result = []
        for i, score in top_scenics:
            result.append({
                'æ™¯åŒºåç§°': self.scenic_reviews.iloc[i]['æ™¯åŒºåç§°'],
                'ç›¸ä¼¼åº¦å¾—åˆ†': score
            })

        return pd.DataFrame(result)

    def hybrid_recommend(self, user_id, scenic_name, top_n=5, content_weight=0.7, collab_weight=0.3):
        # å†…å®¹æŽ¨è
        content_rec = self.get_similar_scenics(scenic_name, top_n * 2)

        # ååŒè¿‡æ»¤æŽ¨è
        items = self.df['æ™¯åŒºåç§°'].unique()
        user_items = self.df[self.df['ç”¨æˆ·ID'] == user_id]['æ™¯åŒºåç§°'].tolist()
        unrated_items = [item for item in items if item not in user_items]

        predictions = []
        for item in unrated_items:
            pred = self.algo.predict(user_id, item)
            predictions.append((item, pred.est))

        collab_rec = pd.DataFrame(predictions, columns=['æ™¯åŒºåç§°', 'é¢„æµ‹è¯„åˆ†'])
        collab_rec = collab_rec.sort_values('é¢„æµ‹è¯„åˆ†', ascending=False).head(top_n * 2)

        # æ··åˆæŽ¨è
        merged_rec = pd.merge(content_rec, collab_rec, on='æ™¯åŒºåç§°', how='outer')
        merged_rec['ç»¼åˆå¾—åˆ†'] = (content_weight * merged_rec['ç›¸ä¼¼åº¦å¾—åˆ†'].fillna(0) +
                                  collab_weight * merged_rec['é¢„æµ‹è¯„åˆ†'].fillna(0))

        return merged_rec.sort_values('ç»¼åˆå¾—åˆ†', ascending=False).head(top_n)

    def get_scenic_details(self, scenic_name):
        return self.df[self.df['æ™¯åŒºåç§°'] == scenic_name].iloc[0]

    def get_user_recommendations(self, user_id, top_n=5):
        items = self.df['æ™¯åŒºåç§°'].unique()
        user_items = self.df[self.df['ç”¨æˆ·ID'] == user_id]['æ™¯åŒºåç§°'].tolist()
        unrated_items = [item for item in items if item not in user_items]

        predictions = []
        for item in unrated_items:
            pred = self.algo.predict(user_id, item)
            predictions.append((item, pred.est))

        recommendations = pd.DataFrame(predictions, columns=['æ™¯åŒºåç§°', 'é¢„æµ‹è¯„åˆ†'])
        return recommendations.sort_values('é¢„æµ‹è¯„åˆ†', ascending=False).head(top_n)

    def get_user_reviewed_scenics(self, user_id):
        return self.df[self.df['ç”¨æˆ·ID'] == user_id]['æ™¯åŒºåç§°'].unique()

    def get_scenic_comments(self, scenic_name, top_n=3):
        return self.df[self.df['æ™¯åŒºåç§°'] == scenic_name]['è¯„è®ºå†…å®¹'].dropna().head(top_n)

    def get_scenic_keywords(self, scenic_name, top_n=10):
        keywords = self.get_scenic_details(scenic_name).get('å…³é”®è¯', [])
        return keywords[:top_n] if keywords else []

    def get_popular_scenics(self, top_n=5):
        return self.df.groupby('æ™¯åŒºåç§°')['ç”¨æˆ·ID'].count().sort_values(ascending=False).head(top_n)

    def get_regional_distribution(self):
        return self.df.groupby('çœä»½')['æ™¯åŒºåç§°'].nunique().sort_values(ascending=False)

    def get_average_ratings(self):
        return self.df.groupby('æ™¯åŒºåç§°')['æ˜ å°„è¯„åˆ†'].mean().sort_values(ascending=False)


# ä¸»ç¨‹åºæµç¨‹
recommender = ScenicRecommender()

with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®å’Œè®­ç»ƒæ¨¡åž‹..."):
    success = recommender.load_and_preprocess_data('å…¨å›½5Açº§æ™¯åŒº.xlsx', 'æ™¯åŒºè¯„è®ºæ•°æ®é›†.xlsx')

    if success:
        success = recommender.train_model()

        if success:
            st.success(f"æ•°æ®åŠ è½½å’Œæ¨¡åž‹è®­ç»ƒå®Œæˆï¼è®­ç»ƒè€—æ—¶: {recommender.training_time:.2f}ç§’")

            # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯
            st.subheader("æ•°æ®ç»Ÿè®¡ä¿¡æ¯")
            col1, col2, col3 = st.columns(3)
            col1.metric("æ™¯åŒºæ•°é‡", len(recommender.df['æ™¯åŒºåç§°'].unique()))
            col2.metric("ç”¨æˆ·è¯„è®ºæ•°é‡", len(recommender.df))
            col3.metric("ç”¨æˆ·æ•°é‡", len(recommender.df['ç”¨æˆ·ID'].unique()))

            # æ•°æ®å¯è§†åŒ–
            st.subheader("æ•°æ®å¯è§†åŒ–")
            tab1, tab2, tab3 = st.tabs(["æ™¯åŒºåˆ†å¸ƒ", "è¯„åˆ†åˆ†å¸ƒ", "çƒ­é—¨æ™¯åŒº"])

            with tab1:
                regional_distribution = recommender.get_regional_distribution()
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.barplot(x=regional_distribution.index, y=regional_distribution.values, ax=ax)
                plt.xticks(rotation=45)
                plt.title("å„çœ5Açº§æ™¯åŒºæ•°é‡åˆ†å¸ƒ")
                st.pyplot(fig)

            with tab2:
                ratings = recommender.get_average_ratings()
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.histplot(ratings.values, bins=20, kde=True, ax=ax)
                plt.title("æ™¯åŒºè¯„åˆ†åˆ†å¸ƒ")
                st.pyplot(fig)

            with tab3:
                popular_scenics = recommender.get_popular_scenics(10)
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.barplot(x=popular_scenics.values, y=popular_scenics.index, ax=ax)
                plt.title("çƒ­é—¨æ™¯åŒºï¼ˆè¯„è®ºæ•°é‡ï¼‰")
                st.pyplot(fig)

            # æŽ¨èç³»ç»Ÿç•Œé¢
            st.subheader("æ™¯åŒºæŽ¨è")
            recommendation_type = st.selectbox(
                "æŽ¨èç±»åž‹",
                ["åŸºäºŽå†…å®¹çš„æŽ¨è", "åŸºäºŽç”¨æˆ·çš„æŽ¨è", "æ··åˆæŽ¨è"]
            )

            if recommendation_type == "åŸºäºŽå†…å®¹çš„æŽ¨è":
                selected_scenic = st.selectbox(
                    "é€‰æ‹©æ™¯åŒº",
                    sorted(recommender.df['æ™¯åŒºåç§°'].unique())
                )
                top_n = st.slider("æŽ¨èæ•°é‡", 1, 10, 5)

                if st.button("èŽ·å–æŽ¨è"):
                    with st.spinner("æ­£åœ¨ç”ŸæˆæŽ¨è..."):
                        recommendations = recommender.get_similar_scenics(selected_scenic, top_n)
                        st.write(f"ä¸Ž **{selected_scenic}** ç›¸ä¼¼çš„æ™¯åŒº:")
                        st.dataframe(recommendations.style.format({"ç›¸ä¼¼åº¦å¾—åˆ†": "{:.2f}"}))

            elif recommendation_type == "åŸºäºŽç”¨æˆ·çš„æŽ¨è":
                user_id = st.text_input("è¾“å…¥ç”¨æˆ·ID", "11111")
                top_n = st.slider("æŽ¨èæ•°é‡", 1, 10, 5)

                if st.button("èŽ·å–æŽ¨è"):
                    with st.spinner("æ­£åœ¨ç”ŸæˆæŽ¨è..."):
                        # èŽ·å–ç”¨æˆ·å·²ç»è¯„ä»·è¿‡çš„æ™¯åŒº
                        user_scenics = recommender.get_user_reviewed_scenics(user_id)

                        if len(user_scenics) == 0:
                            st.warning(f"ç”¨æˆ· {user_id} æ²¡æœ‰è¯„ä»·è®°å½•ï¼Œæ— æ³•è¿›è¡Œä¸ªæ€§åŒ–æŽ¨èã€‚")
                        else:
                            st.write(f"ç”¨æˆ· {user_id} å·²è¯„ä»·çš„æ™¯åŒº:")
                            st.write(", ".join(user_scenics))

                            # ç”ŸæˆæŽ¨è
                            recommendations = recommender.get_user_recommendations(user_id, top_n)

                            st.write(f"ä¸ºç”¨æˆ· {user_id} æŽ¨èçš„æ™¯åŒº:")
                            st.dataframe(recommendations.style.format({"é¢„æµ‹è¯„åˆ†": "{:.2f}"}))

            else:  # æ··åˆæŽ¨è
                user_id = st.text_input("è¾“å…¥ç”¨æˆ·ID", "11111")
                selected_scenic = st.selectbox(
                    "é€‰æ‹©å‚è€ƒæ™¯åŒº",
                    sorted(recommender.df['æ™¯åŒºåç§°'].unique())
                )
                top_n = st.slider("æŽ¨èæ•°é‡", 1, 10, 5)
                content_weight = st.slider("å†…å®¹æŽ¨èæƒé‡", 0.0, 1.0, 0.7, 0.1)
                collab_weight = st.slider("ååŒè¿‡æ»¤æƒé‡", 0.0, 1.0, 0.3, 0.1)

                if st.button("èŽ·å–æŽ¨è"):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆæ··åˆæŽ¨è..."):
                        recommendations = recommender.hybrid_recommend(
                            user_id,
                            selected_scenic,
                            top_n,
                            content_weight,
                            collab_weight
                        )

                        st.write(f"æ··åˆæŽ¨èç»“æžœ (ç”¨æˆ· {user_id} å¯èƒ½å–œæ¬¢çš„ç±»ä¼¼ **{selected_scenic}** çš„æ™¯åŒº):")
                        st.dataframe(recommendations[['æ™¯åŒºåç§°', 'ç›¸ä¼¼åº¦å¾—åˆ†', 'é¢„æµ‹è¯„åˆ†', 'ç»¼åˆå¾—åˆ†']].style.format({
                            "ç›¸ä¼¼åº¦å¾—åˆ†": "{:.2f}",
                            "é¢„æµ‹è¯„åˆ†": "{:.2f}",
                            "ç»¼åˆå¾—åˆ†": "{:.2f}"
                        }))

            # æ™¯åŒºè¯¦æƒ…æŸ¥çœ‹
            st.subheader("æ™¯åŒºè¯¦æƒ…")
            selected_scenic_detail = st.selectbox(
                "é€‰æ‹©æ™¯åŒºæŸ¥çœ‹è¯¦æƒ…",
                sorted(recommender.df['æ™¯åŒºåç§°'].unique())
            )

            if st.button("æŸ¥çœ‹è¯¦æƒ…"):
                with st.spinner("æ­£åœ¨åŠ è½½æ™¯åŒºè¯¦æƒ…..."):
                    try:
                        scenic_details = recommender.get_scenic_details(selected_scenic_detail)
                        st.write(f"### {scenic_details['æ™¯åŒºåç§°']}")

                        col1, col2, col3 = st.columns(3)
                        col1.metric("å¹³å‡è¯„åˆ†", f"{scenic_details['æ˜ å°„è¯„åˆ†']:.1f}/5.0")
                        col1.metric("è¯„è®ºæ•°é‡", len(recommender.get_scenic_comments(selected_scenic_detail)))
                        col2.metric("çœä»½", scenic_details.get('çœä»½', 'æœªçŸ¥'))
                        col2.metric("åŸŽå¸‚", scenic_details.get('åŸŽå¸‚', 'æœªçŸ¥'))

                        st.write("**æ™¯åŒºç®€ä»‹**")
                        st.write(scenic_details.get('æ™¯åŒºç®€ä»‹', 'æš‚æ— ç®€ä»‹'))

                        st.write("**çƒ­é—¨è¯„è®º**")
                        comments = recommender.get_scenic_comments(selected_scenic_detail)
                        for i, comment in enumerate(comments):
                            st.markdown(f"> {comment}")

                        st.write("**å…³é”®è¯**")
                        keywords = recommender.get_scenic_keywords(selected_scenic_detail)
                        if keywords:
                            st.markdown(" ".join([f"#{word}" for word in keywords]))

                        # è¯„è®ºæƒ…æ„Ÿåˆ†æž
                        st.write("**è¯„è®ºæƒ…æ„Ÿåˆ†æž**")
                        scenic_comments = recommender.df[recommender.df['æ™¯åŒºåç§°'] == selected_scenic_detail]
                        sentiment_scores = scenic_comments['æƒ…æ„Ÿå¾—åˆ†'].dropna()

                        if len(sentiment_scores) > 0:
                            fig, ax = plt.subplots(figsize=(8, 4))
                            sns.histplot(sentiment_scores, bins=20, kde=True, ax=ax)
                            plt.title("è¯„è®ºæƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ")
                            plt.xlabel("æƒ…æ„Ÿå¾—åˆ† (0=è´Ÿé¢, 1=æ­£é¢)")
                            st.pyplot(fig)

                            positive_ratio = len(sentiment_scores[sentiment_scores > 0.7]) / len(sentiment_scores)
                            neutral_ratio = len(
                                sentiment_scores[(sentiment_scores >= 0.3) & (sentiment_scores <= 0.7)]) / len(
                                sentiment_scores)
                            negative_ratio = len(sentiment_scores[sentiment_scores < 0.3]) / len(sentiment_scores)

                            col1, col2, col3 = st.columns(3)
                            col1.metric("ç§¯æžè¯„è®ºæ¯”ä¾‹", f"{positive_ratio:.2%}")
                            col2.metric("ä¸­æ€§è¯„è®ºæ¯”ä¾‹", f"{neutral_ratio:.2%}")
                            col3.metric("æ¶ˆæžè¯„è®ºæ¯”ä¾‹", f"{negative_ratio:.2%}")
                    except Exception as e:
                        st.error(f"èŽ·å–æ™¯åŒºè¯¦æƒ…å¤±è´¥: {e}")
else:
st.error("æ•°æ®åŠ è½½æˆ–æ¨¡åž‹è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶å’Œä¾èµ–åº“ã€‚")